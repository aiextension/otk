<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>API Reference - Open OTK</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.0/font/bootstrap-icons.css">
    <link rel="stylesheet" href="css/style.css">
</head>
<body>
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top">
        <div class="container">
            <a class="navbar-brand fw-bold" href="index.html"><i class="bi bi-box-seam"></i> Open OTK</a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarNav">
                <ul class="navbar-nav ms-auto">
                    <li class="nav-item"><a class="nav-link" href="index.html">Home</a></li>
                    <li class="nav-item"><a class="nav-link" href="installation.html">Installation</a></li>
                    <li class="nav-item"><a class="nav-link" href="quickstart.html">Quick Start</a></li>
                    <li class="nav-item"><a class="nav-link active" href="api.html">API</a></li>
                    <li class="nav-item"><a class="nav-link" href="examples.html">Examples</a></li>
                    <li class="nav-item"><a class="nav-link" href="https://github.com/aiextension/open-otk" target="_blank"><i class="bi bi-github"></i> GitHub</a></li>
                </ul>
            </div>
        </div>
    </nav>

    <div class="container content-section">
        <div class="row">
            <div class="col-lg-3">
                <div class="sidebar">
                    <nav class="nav flex-column">
                        <a class="nav-link active" href="#ollamaclient">OllamaClient</a>
                        <a class="nav-link" href="#chatsession">ChatSession</a>
                        <a class="nav-link" href="#modelmanager">ModelManager</a>
                        <a class="nav-link" href="#response-handlers">Response Handlers</a>
                        <a class="nav-link" href="#customization">Customization</a>
                        <a class="nav-link" href="#utilities">Utilities</a>
                    </nav>
                </div>
            </div>

            <div class="col-lg-9">
                <h1 class="mb-4">API Reference</h1>
                <p class="lead">Complete API documentation for Open OTK</p>

                <section id="ollamaclient">
                    <h2>OllamaClient</h2>
                    <p>Main client for interacting with Ollama.</p>

                    <h3>Initialization</h3>
                    <pre class="bg-dark text-light p-3 rounded"><code>from otk import OllamaClient

client = OllamaClient(host="http://localhost:11434")</code></pre>

                    <h3>Methods</h3>
                    <div class="table-responsive">
                        <table class="table table-bordered">
                            <thead>
                                <tr>
                                    <th>Method</th>
                                    <th>Description</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td><code>generate(model, prompt, **kwargs)</code></td>
                                    <td>Generate text from a prompt</td>
                                </tr>
                                <tr>
                                    <td><code>stream_generate(model, prompt, **kwargs)</code></td>
                                    <td>Stream generation in real-time</td>
                                </tr>
                                <tr>
                                    <td><code>chat(model, messages, **kwargs)</code></td>
                                    <td>Chat completion with message history</td>
                                </tr>
                                <tr>
                                    <td><code>stream_chat(model, messages, **kwargs)</code></td>
                                    <td>Stream chat responses</td>
                                </tr>
                                <tr>
                                    <td><code>embeddings(model, text)</code></td>
                                    <td>Generate text embeddings</td>
                                </tr>
                                <tr>
                                    <td><code>is_running()</code></td>
                                    <td>Check if Ollama is running</td>
                                </tr>
                            </tbody>
                        </table>
                    </div>

                    <h3>Example</h3>
                    <pre class="bg-dark text-light p-3 rounded"><code># Generate with options
response = client.generate(
    model="llama2",
    prompt="Write a haiku",
    temperature=0.8,
    max_tokens=100
)

# Streaming
for chunk in client.stream_generate("llama2", "Tell a story"):
    print(chunk, end='', flush=True)</code></pre>
                </section>

                <section id="chatsession">
                    <h2>ChatSession</h2>
                    <p>Manage conversation context with automatic response processing.</p>

                    <h3>Initialization</h3>
                    <pre class="bg-dark text-light p-3 rounded"><code>from otk import ChatSession

session = ChatSession(
    model="llama2",
    system_message="You are a helpful assistant",
    temperature=0.7,
    max_history=50,
    auto_process=True
)</code></pre>

                    <h3>Methods</h3>
                    <div class="table-responsive">
                        <table class="table table-bordered">
                            <thead>
                                <tr>
                                    <th>Method</th>
                                    <th>Description</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td><code>send(message)</code></td>
                                    <td>Send a message and get response</td>
                                </tr>
                                <tr>
                                    <td><code>send_stream(message)</code></td>
                                    <td>Stream response for a message</td>
                                </tr>
                                <tr>
                                    <td><code>get_history()</code></td>
                                    <td>Get conversation history</td>
                                </tr>
                                <tr>
                                    <td><code>clear_history()</code></td>
                                    <td>Clear conversation history</td>
                                </tr>
                                <tr>
                                    <td><code>get_last_thinking()</code></td>
                                    <td>Get thinking process from last response</td>
                                </tr>
                                <tr>
                                    <td><code>export_history(filename)</code></td>
                                    <td>Export chat history to file</td>
                                </tr>
                                <tr>
                                    <td><code>load_history(filename)</code></td>
                                    <td>Load chat history from file</td>
                                </tr>
                            </tbody>
                        </table>
                    </div>
                </section>

                <section id="modelmanager">
                    <h2>ModelManager</h2>
                    <p>Manage Ollama models.</p>

                    <pre class="bg-dark text-light p-3 rounded"><code>from otk import ModelManager

manager = ModelManager()

# List models
models = manager.list_models()

# Pull/install model
manager.pull_model("mistral", stream=True)

# Delete model
manager.delete_model("old-model")

# Check if exists
exists = manager.model_exists("llama2")

# Get model info
info = manager.show_model_info("llama2")</code></pre>
                </section>

                <section id="response-handlers">
                    <h2>Response Handlers</h2>
                    <p>Handle different model response formats automatically.</p>

                    <pre class="bg-dark text-light p-3 rounded"><code>from otk import (
    AutoModelHandler,
    ModelResponseHandler,
    ModelType,
    clean_thinking_tags
)

# Auto-detect model type
auto_handler = AutoModelHandler()
processed = auto_handler.process_response(raw_text, "deepseek-r1")

# Specific handler
handler = ModelResponseHandler(ModelType.THINKING)
processed = handler.process(raw_text)

# Quick utility
clean_text, thinking = clean_thinking_tags(response)</code></pre>

                    <h3>ModelType Enum</h3>
                    <ul>
                        <li><code>ModelType.THINKING</code> - Models with &lt;think&gt; tags (DeepSeek-R1, Qwen)</li>
                        <li><code>ModelType.STANDARD</code> - Standard chat models</li>
                        <li><code>ModelType.CUSTOM</code> - Custom patterns</li>
                    </ul>
                </section>

                <section id="customization">
                    <h2>Customization</h2>
                    
                    <h3>ModelBuilder</h3>
                    <pre class="bg-dark text-light p-3 rounded"><code>from otk import ModelBuilder, HookType

model = (ModelBuilder("llama2")
         .with_preset("creative")
         .with_temperature(0.85)
         .with_max_tokens(500)
         .with_hook(HookType.POST_PROCESS, my_logger)
         .with_post_processor(my_formatter)
         .build())</code></pre>

                    <h3>ModelExperiment</h3>
                    <pre class="bg-dark text-light p-3 rounded"><code>from otk import ModelExperiment

experiment = ModelExperiment()

# Compare models
result = experiment.compare_models(
    models=["llama2", "mistral"],
    prompt="Explain AI"
)

# Benchmark
stats = experiment.benchmark("llama2", "Test", iterations=10)</code></pre>
                </section>

                <section id="utilities">
                    <h2>Utility Functions</h2>
                    <pre class="bg-dark text-light p-3 rounded"><code>from otk import (
    estimate_tokens,
    chunk_text,
    extract_code_blocks,
    format_response
)

# Token estimation
tokens = estimate_tokens(text)

# Text chunking
chunks = chunk_text(text, chunk_size=1000, overlap=100)

# Extract code
code_blocks = extract_code_blocks(markdown_text)

# Format output
formatted = format_response(long_text, max_width=80)</code></pre>
                </section>

                <div class="alert alert-info mt-4">
                    <i class="bi bi-book"></i> <strong>More Details:</strong> Check the source code on <a href="https://github.com/aiextension/open-otk" target="_blank">GitHub</a> for complete API documentation.
                </div>

                <div class="mt-5">
                    <a href="examples.html" class="btn btn-primary">
                        Next: View Examples <i class="bi bi-arrow-right"></i>
                    </a>
                </div>
            </div>
        </div>
    </div>

    <footer class="bg-dark text-light py-4 mt-5">
        <div class="container text-center">
            <p class="mb-0">&copy; 2026 Open OTK. Licensed under MIT License.</p>
        </div>
    </footer>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
    <script src="js/script.js"></script>
</body>
</html>
